# PBR ControlNet 配置文件
# 基于 SD 1.5 + ControlNet

model:
  target: scripts.models.pbr_controlnet.PBRControlLDM
  params:
    # 基础参数（从 cldm_v15.yaml 继承）
    linear_start: 0.00085
    linear_end: 0.0120
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    first_stage_key: "jpg"
    cond_stage_key: "txt"
    control_key: "hint"
    image_size: 64
    channels: 4
    cond_stage_trainable: false
    conditioning_key: crossattn
    monitor: val/loss_simple_ema
    scale_factor: 0.18215
    use_ema: False
    only_mid_control: False
    
    # PBR specific parameters (cleaner approach)
    latent_code_dim: 256
    use_latent_code: true
    loss_type: 'mixed'  # 'l1', 'l2', or 'mixed'
    pixel_loss_weight: 0.1  # Weight for pixel-level PBR reconstruction losses
    pixel_loss_frequency: 10  # Compute pixel loss every N steps (0 = disabled, 10 = every 10 steps)
    
    # ControlNet 配置
    control_stage_config:
      target: submodule.controlnet.cldm.cldm.ControlNet
      params:
        use_checkpoint: True
        image_size: 32
        in_channels: 4
        hint_channels: 3  # mask 是 3 通道 (RGB)
        model_channels: 320
        attention_resolutions: [4, 2, 1]
        num_res_blocks: 2
        channel_mult: [1, 2, 4, 4]
        num_heads: 8  # 使用 num_heads 而不是 num_head_channels，以匹配 SD 1.5
        use_spatial_transformer: True
        use_linear_in_transformer: False  # 改为 False 以匹配 SD 1.5 预训练权重（使用 2D 卷积）
        transformer_depth: 1
        context_dim: 768  # SD 1.5 的 context_dim
        legacy: False
    
    # UNet 配置
    unet_config:
      target: submodule.controlnet.cldm.cldm.ControlledUnetModel
      params:
        use_checkpoint: True
        image_size: 32
        in_channels: 4
        out_channels: 4  # VAE latent space 是 4 通道
        model_channels: 320
        attention_resolutions: [4, 2, 1]
        num_res_blocks: 2
        channel_mult: [1, 2, 4, 4]
        num_heads: 8  # 使用 num_heads 而不是 num_head_channels，以匹配 SD 1.5
        use_spatial_transformer: True
        use_linear_in_transformer: False  # 改为 False 以匹配 SD 1.5 预训练权重（使用 2D 卷积）
        transformer_depth: 1
        context_dim: 768
        legacy: False
    
    # VAE 配置（first stage）
    first_stage_config:
      target: submodule.controlnet.ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3  # Input is RGB (albedo) - use pretrained weights
          out_ch: 3      # Output is RGB (albedo) - use pretrained weights
          ch: 128
          ch_mult: [1, 2, 4, 4]
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity
    
    # Text encoder 配置（虽然我们用 latent code，但保留这个用于兼容）
    cond_stage_config:
      target: submodule.controlnet.ldm.modules.encoders.modules.FrozenCLIPEmbedder
      params:
        freeze: True

# 训练参数
training:
  batch_size: 8
  learning_rate: 1e-5
  num_epochs: 1000
  sd_locked: true  # 冻结 SD 权重
  only_mid_control: false

